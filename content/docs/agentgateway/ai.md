---
title: AI for LLM consumption
weight: 30
---

With agentgateway, you can route directly to LLM cloud providers, such as OpenAI.

For more information, see the AI Gateway section of the docs.

{{< cards >}}
  {{< card link="about" title="About AI Gateway" >}}
  {{< card link="setup" title="Set up AI Gateway" >}}
  {{< card link="cloud-providers" title="LLM cloud providers" >}}
  {{< card link="ollama" title="Ollama for local LLMs" >}}
  {{< card link="auth" title="Authenticate LLM providers" >}}
  {{< card link="functions" title="Function calling" >}}
  {{< card link="cleanup" title="Cleanup" >}}
  {{< card link="/docs/integrations/inference-extension" title="Inference Extension for local LLMs" icon="bookmark" >}}
{{< /cards >}}
